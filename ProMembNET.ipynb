{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MDAnalysis as md # distances in Angstroem\n",
    "from MDAnalysis.lib.pkdtree import PeriodicKDTree\n",
    "from MDAnalysis.lib.distances import distance_array\n",
    "from MDAnalysis.analysis.dihedrals import Ramachandran\n",
    "from MDAnalysis.analysis.hbonds.hbond_analysis import HydrogenBondAnalysis as HBA\n",
    "from sklearn.cluster import KMeans\n",
    "import mdtraj # necessary for dssp\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import h5py as h5\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#u = md.Universe('traj_nowater.pdb', 'traj_nowater_test.xtc')\n",
    "#int(len(u.universe.select_atoms(\"index 627:40157\"))/134)\n",
    "#int(len(u.universe.select_atoms(\"index 761:40157\"))/294)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransitionNetworks:\n",
    "    topology = None\n",
    "    trajectory = None\n",
    "    state = []\n",
    "    nLigandChains = 0  \n",
    "    nProteinChains = 0\n",
    "\n",
    "    \n",
    "    \n",
    "    \"\"\"The descriptors and corresponding cutoffs to use for constructing the transition matrix.\"\"\"\n",
    "    descriptors = {}\n",
    "    \n",
    "    def __init__(self, top=topology, traj=trajectory, nLigandChains=nLigandChains,\\\n",
    "                 nProteinChains=nProteinChains,desc=descriptors, state=state,\\\n",
    "                 h5File='transitionNetwork.hdf5'):\n",
    "        \n",
    "        self.top = top\n",
    "        self.traj = traj\n",
    "        self.universe = md.Universe(top, traj)\n",
    "        \n",
    "        self.nLigandChains = nLigandChains\n",
    "        self.nAtomsPerLigandChain = int(len(self.universe.select_atoms(\"resname POPC and not resid 43\"))/nLigandChains)\n",
    "        self.nResiduesPerLigandChain = int(len(self.universe.select_atoms(\"resname POPC and not resid 43\").residues)/nLigandChains)\n",
    "\n",
    "        self.nProteinChains = nProteinChains\n",
    "        self.nAtomsPerProteinChain = int(len(self.universe.select_atoms(\"protein\"))/nProteinChains)\n",
    "        self.nResiduesProteinPerChain = int(len(self.universe.select_atoms(\"protein\").residues)/nProteinChains)\n",
    "\n",
    "        self.nFrames = self.universe.trajectory.n_frames\n",
    "        self.state = state\n",
    "        self.h5File = h5File\n",
    "        \n",
    "        \"\"\"Sort the descriptors dictionary by cutoffs in decreasing order.\"\"\"\n",
    "        self.descriptors = {k: v for k, v in sorted(desc.items(), key=lambda item: -item[1])}\n",
    "\n",
    "        \"\"\"Generate array with cutoff values in decreasing order.\"\"\"\n",
    "        self.cutoffs = np.unique(list(self.descriptors.values()))[::-1]\n",
    "        \n",
    "        \"\"\"Generate array to connect atom indices with residue names.\"\"\"\n",
    "        self.resnames = self.universe.atoms.resnames\n",
    "        \n",
    "        \"\"\"Generate array to connect atom indices with residue indices.\"\"\"\n",
    "        self.resindices = self.universe.atoms.resindices    \n",
    "    \n",
    "    def _intermolecularContactPairs(self):\n",
    "        \"\"\"The largest cutoff value 'cutoff0' defines the search distance for the k-d tree.\"\"\"\n",
    "        cutoff0 = self.cutoffs[0]\n",
    "        \n",
    "        \"\"\"All other cutoffs are stored in the array cutoffs1\"\"\"\n",
    "        cutoffs1 = self.cutoffs[1:]\n",
    "\n",
    "        with h5.File(self.h5File, 'a') as f:\n",
    "            \"\"\"Create/Check if group 'contactPairs' is present in the file. Structure\n",
    "            of this group is: (nFrames, nCutoffs, contactPairs[cutoff]).\"\"\"\n",
    "            group = f.require_group(name='contactPairs')\n",
    "            \n",
    "            for frameIdx, frame in enumerate(self.universe.trajectory):\n",
    "                frameIdx = str(frameIdx)\n",
    "                \n",
    "                \"\"\"Extract the unit cell information 'box' and the concatenated positions\n",
    "                'pos Concatenated' for every frame.\"\"\"\n",
    "                box = frame.dimensions\n",
    "                posConcatenated = frame.positions\n",
    "                \n",
    "                \"\"\"Initialize the periodic k-d tree 'tree' with the unit cell information.\n",
    "                From MD analysis online documentation:\n",
    "                Number of entries in leafs of the KDTree. If you suffer poor performance \n",
    "                you can play around with this number. Increasing the leafsize will speed\n",
    "                up the construction of the KDTree but slow down the search.\"\"\"\n",
    "                tree = PeriodicKDTree(box=box, leafsize=5)\n",
    "                \n",
    "                \"\"\"Reshape the positions array from shape (nAtomsPerChain*nChains, 3) to\n",
    "                (nChains, nAtomsPerChain, 3) 'pos' seperately for protein and ligand.\"\"\"\n",
    "                \n",
    "                posProtein = np.split(posConcatenated[:self.nProteinChains*self.nAtomsPerProteinChain], self.nProteinChains)\n",
    "                #print(posProtein)\n",
    "                posLigand = np.split(posConcatenated[761:40157], self.nLigandChains)\n",
    "                \n",
    "                \"\"\"Build the k-d tree using the coordinates of one chain and then search\n",
    "                all intermolecular contacts using the coordinates of the remaining chains.\"\"\"\n",
    "                contactPairs = list([] for d in self.cutoffs)\n",
    "\n",
    "                for excludeChain in range(self.nProteinChains):\n",
    "                    \n",
    "                    \"\"\"Extract the coordinates of one protein chain.\"\"\"\n",
    "                    excludePos = posProtein[excludeChain]\n",
    "\n",
    "                    \"\"\"Build the k-d tree using these coordinates. From MD analysis online\n",
    "                    documentation: 'cutoff': Specified cutoff distance to create duplicate images.\n",
    "                    Typically equivalent to the desired search radius or the maximum of the \n",
    "                    desired cutoff radius.\"\"\"\n",
    "                    tree.set_coords(excludePos, cutoff=cutoff0)\n",
    "\n",
    "                    \"\"\"Extract all intermolecular contact pairs within the cutoff0 and correct atom\n",
    "                    indicies.\"\"\"\n",
    "                    for ligandChainIdx, includePos in enumerate(posLigand):\n",
    "                        for pair in tree.search_tree(includePos, cutoff0):                                        \n",
    "                                                        \n",
    "                            atomIdxLigand = pair[0]                            \n",
    "                            atomIdxProtein = pair[1]\n",
    "    \n",
    "                            \"\"\"Compute the exact distance of this intermolecular distance pair using pbc.\"\"\"\n",
    "                            distance = distance_array(posLigand[ligandChainIdx][atomIdxLigand],\n",
    "                                                      posProtein[excludeChain][atomIdxProtein],\n",
    "                                                      box=box)[0][0]\n",
    "\n",
    "                            \"\"\"Compare the calculated distance with the given cutoffs, stop if cutoff is\n",
    "                            greater than the given value. 'depth' allows to return the 'stop cutoff' value\n",
    "                            by self.cutoffs[depth].\"\"\"\n",
    "                            depth = 0\n",
    "                            for cValue in cutoffs1:\n",
    "                                if (distance < cValue):\n",
    "                                    depth += 1\n",
    "                                else:\n",
    "                                    break\n",
    "                                    \n",
    "                            globalAtomIdxLigand = pair[0] + self.nAtomsPerLigandChain*ligandChainIdx + self.nAtomsPerProteinChain*self.nProteinChains\n",
    "                            globalAtomIdxProtein = pair[1] + self.nAtomsPerProteinChain*excludeChain\n",
    "                                                       \n",
    "                            \"\"\"Append the contact pair to the last undercut cutoff value array.\"\"\"\n",
    "                            contactPairs[depth].append(sorted([globalAtomIdxProtein, globalAtomIdxLigand])) \n",
    "                    print(contactPairs)\n",
    "                    \"\"\"Store the intermolecular contact pairs array in the hdf5 file.\"\"\"\n",
    "                    subGroup = group.require_group(name=frameIdx)\n",
    "                    for depth, data in enumerate(contactPairs):\n",
    "                        subGroup.create_dataset(name=str(self.cutoffs[depth]), data=data)\n",
    "    \n",
    "    \n",
    "    def _residuesWithAttribute(self, descriptorName=None, attribute=None):\n",
    "        \"\"\"The user can define an attribute group by augmentation or modification of\n",
    "        the 'attributes' dictionary.\"\"\"\n",
    "        attributes = {'hydrophobic': ['GLY', 'ALA', 'VAL', 'LEU', 'ILE', 'PRO', 'PHE', 'MET', 'TRP'],\n",
    "                      'polar': ['SER', 'THR', 'CYS', 'ASN', 'GLN', 'TYR'],\n",
    "                      'charged':['ARG','HIS', 'LYS','ASP', 'GLU'],\n",
    "                      'all' : ['GLY', 'ALA', 'VAL', 'LEU', 'ILE', 'PRO', 'PHE', 'MET', 'TRP','SER', 'THR', 'CYS', 'ASN', 'GLN', 'TYR','ARG','HIS', 'LYS','ASP', 'GLU']}\n",
    "        residuesWithAttribute = attributes[attribute]\n",
    "    \n",
    "    \n",
    "        \"\"\"Get the cutoff value for the descriptor function.\"\"\"\n",
    "        cutoff = self.descriptors[descriptorName]\n",
    "        \n",
    "        \"\"\"Open the hdf5 file and create the group 'descriptorName' to store all information\n",
    "        for this descriptor function. The structure of this group is (nFrames, nChains, any).\"\"\"\n",
    "        with h5.File(self.h5File, 'a') as f:\n",
    "            group = f.require_group(name=descriptorName+str(cutoff))\n",
    "\n",
    "            \"\"\"Extract the contact pairs for every frame for the descriptor.\"\"\"\n",
    "            for frameIdx in f['contactPairs']:\n",
    "                frameIdx = str(frameIdx)\n",
    "                contactPairs = list(f['contactPairs'][frameIdx][str(cutoff)])\n",
    "                \n",
    "\n",
    "                \"\"\"Array to be filled with information to identify which residues are in contact \n",
    "                within the cutoff value distance. Set is chosen because it has the helpful add\n",
    "                feature, means that if the chain index is already included it is not appended\n",
    "                multiple times, which would be the case when appending to a list.\"\"\"\n",
    "                residuesInContact = []\n",
    "\n",
    "                \"\"\"Get the residue names of the atom indices and see if they belong to the\n",
    "                chosen attribute.\"\"\"\n",
    "                for atomIdxChainA, atomIdxChainB in contactPairs:\n",
    "                    residueNameA = self.resnames[atomIdxChainA]\n",
    "                    residueNameB = self.resnames[atomIdxChainB]\n",
    "\n",
    "                    if (residueNameA in residuesWithAttribute):\n",
    "                        if (residueNameB in residuesWithAttribute):\n",
    "                            \"\"\"Build the 'residuePair' and check if contact between both residues\n",
    "                            has already been recognized. If not, add it to the array 'residuesInContact'\n",
    "                            and increase the counter 'resiudesInContactCounter'.\"\"\"\n",
    "                            residueIdxA=self.resindices[atomIdxChainA]\n",
    "                            residueIdxB=self.resindices[atomIdxChainB]\n",
    "                            residuePair = [residueIdxA, residueIdxB]\n",
    "                            if residuePair not in residuesInContact:\n",
    "                                residuesInContact.append(residuePair)\n",
    "                      \n",
    "                \"\"\"Export the data in the hdf5 file.\"\"\"\n",
    "                group.create_dataset(name=frameIdx, data=np.array([len(residuesInContact)]))\n",
    "                \n",
    "    \n",
    "    def _hydrophobicContacts(self):\n",
    "        self._residuesWithAttribute(descriptorName='hydrophobicContacts', attribute='hydrophobic')\n",
    "        \n",
    "    def _allContacts(self):\n",
    "        self._residuesWithAttribute(descriptorName='allContacts', attribute='all')\n",
    "    \n",
    "    def _polarContacts(self):\n",
    "        self._residuesWithAttribute(descriptorName='polarContacts', attribute='polar')\n",
    "    \n",
    "    def _chargedContacts(self):\n",
    "        self._residuesWithAttribute(descriptorName='chargedContacts', attribute='charged')\n",
    "                        \n",
    "    def _hbondContacts(self):        \n",
    "        \n",
    "        hbonds = HBA(universe=self.universe)\n",
    "        hbonds.run()\n",
    "        \n",
    "        names = [atom.name for atom in self.universe.atoms]\n",
    "        protein = [[], []]\n",
    "        ligand = [[], []]\n",
    "\n",
    "        for idx, name in enumerate(names):\n",
    "            if name in hbonds.donors:\n",
    "                if idx < self.nProteinChains*self.nAtomsPerProteinChain:\n",
    "                    protein[0].append(idx)\n",
    "                else:\n",
    "                    ligand[0].append(idx)\n",
    "\n",
    "            elif name in hbonds.acceptors:\n",
    "                if idx < self.nProteinChains*self.nAtomsPerProteinChain:\n",
    "                    protein[1].append(idx)\n",
    "                else:\n",
    "                    ligand[1].append(idx)\n",
    "\n",
    "        hbondAcceptorsProtein = np.array(protein[1])\n",
    "        hbondDonorsProtein = np.array(protein[0])\n",
    "        hbondAcceptorsLigand = np.array(ligand[1])\n",
    "        hbondDonorsLigand = np.array(ligand[0])\n",
    "\n",
    "        possibleIntermolecularHbondPairs = []\n",
    "        for proteinDonor in hbondDonorsProtein:\n",
    "            for ligandAcceptor in hbondAcceptorsLigand:\n",
    "                possibleIntermolecularHbondPairs.append([proteinDonor, ligandAcceptor])\n",
    "        \n",
    "        for proteinAcceptor in hbondAcceptorsProtein:\n",
    "            for ligandDonor in hbondDonorsLigand:\n",
    "                possibleIntermolecularHbondPairs.append([ligandDonor, proteinAcceptor])\n",
    "\n",
    "        nDifferentHbondPairs = len(possibleIntermolecularHbondPairs)        \n",
    "        \n",
    "        descriptorName='hbondContacts'\n",
    "        \n",
    "        \"\"\"Get the cutoff value for the descriptor function HbondContacts.\"\"\"\n",
    "        cutoff = self.descriptors[descriptorName]\n",
    "\n",
    "        \"\"\"Open the hdf5 file and create the group 'desc' to store all information\n",
    "        for this descriptor function. The structure of this group is (nFrames, nChains).\"\"\"\n",
    "        with h5.File(self.h5File, 'a') as f:\n",
    "            group = f.require_group(name=descriptorName+str(cutoff))\n",
    "\n",
    "            \"\"\"Extract the contact pairs for every frame for the descriptor.\"\"\"\n",
    "            for frameIdx in range(self.nFrames):\n",
    "                hbondContacts = 0\n",
    "                frameIdx = str(frameIdx)\n",
    "                contactPairs = list(f['contactPairs'][frameIdx][str(cutoff)])\n",
    "        \n",
    "                for contactPair in contactPairs:\n",
    "                    for pair in possibleIntermolecularHbondPairs:\n",
    "                        if np.allclose(pair, np.sort(list(contactPair))):\n",
    "                            hbondContacts += 1\n",
    "                            #print(frameIdx+1, pair)\n",
    "\n",
    "                \"\"\"Export the data in the hdf5 file.\"\"\"\n",
    "                group.create_dataset(name=frameIdx, data=np.array([hbondContacts]))\n",
    "                \n",
    "    def _aromaticStacking(self):\n",
    "        aromatics = {'TYR': ['CG', 'CD1', 'CD2', 'CE1', 'CE2', 'CZ'],\n",
    "             'PHE': ['CG', 'CD1', 'CD2', 'CE1', 'CE2', 'CZ'],\n",
    "             'TRP': ['CG', 'CD1', 'CD2', 'CE1', 'CE2', 'CE3', 'CZ2', 'CZ3', 'NE1']\n",
    "            }\n",
    "        \n",
    "        weights_dict = {'TYR': np.array([12.011, 12.011, 12.011, 12.011, 12.011, 12.011]),\n",
    "                   'PHE': np.array([12.011, 12.011, 12.011, 12.011, 12.011, 12.011]),\n",
    "                   'TRP': np.array([12.011, 12.011, 12.011, 12.011, 12.011, 12.011, \n",
    "                                    12.011, 12.011, 14.007])}\n",
    "\n",
    "        ligand_weights = np.array([12.011, 12.011, 12.011, 12.011,\n",
    "                                   12.011, 12.011, 12.011, 12.011,\n",
    "                                   14.007, 12.011]) \n",
    "\n",
    "        \n",
    "        proteinAromaticCindex = []\n",
    "        ring = []\n",
    "        ks = []\n",
    "\n",
    "        count = 0\n",
    "        for residueName in aromatics.keys():\n",
    "            atomNames = aromatics[residueName]\n",
    "            for atom in self.universe.atoms: \n",
    "                if atom.resname == residueName:\n",
    "                    if atom.name in atomNames:\n",
    "                        if count < len(atomNames)-1:\n",
    "                            ring.append(atom.index)\n",
    "                            count +=1\n",
    "                        else:\n",
    "                            ring.append(atom.index)\n",
    "                            proteinAromaticCindex.append(ring)\n",
    "                            ks.append(atom.resname)\n",
    "                            \n",
    "                            ring = []\n",
    "                            count = 0\n",
    "                            \n",
    "        descriptorName='aromaticStacking'\n",
    "        \n",
    "        \"\"\"Get the cutoff value for the descriptor function aromaticStacking.\"\"\"\n",
    "        cutoff = self.descriptors[descriptorName]\n",
    "\n",
    "        \"\"\"Open the hdf5 file and create the group 'desc' to store all information\n",
    "        for this descriptor function. The structure of this group is (nFrames, nChains).\"\"\"\n",
    "        with h5.File(self.h5File, 'a') as f:\n",
    "            group = f.require_group(name=descriptorName+str(cutoff))\n",
    "\n",
    "            \"\"\"Extract the contact pairs for every frame for the descriptor.\"\"\"\n",
    "            for frameIdx, frame in enumerate(self.universe.trajectory):\n",
    "                frameIdx = str(frameIdx)\n",
    "\n",
    "                \"\"\"Extract the unit cell information 'box' and the concatenated positions\n",
    "                'pos Concatenated' for every frame.\"\"\"\n",
    "                box = frame.dimensions\n",
    "                posConcatenated = frame.positions\n",
    "                \n",
    "                \"\"\"Enter the index of aromatic ring of the ligand\"\"\"\n",
    "                ligandAromaticC = posConcatenated[304:314]\n",
    "                ligandAromaticCOM = np.average(ligandAromaticC, weights=ligand_weights, axis=0)\n",
    "\n",
    "\n",
    "                numberOfContacts = 0\n",
    "                for key, aromaticCarbons in zip(ks, proteinAromaticCindex):\n",
    "                    ligandAromaticCOM = np.average(ligandAromaticC, weights=ligand_weights, axis=0)\n",
    "                    proteinRing = posConcatenated[min(aromaticCarbons):max(aromaticCarbons)+1]\n",
    "                    proteinAromaticCOM = np.average(proteinRing, weights=weights_dict[key], axis=0)\n",
    "                    distance = distance_array(ligandAromaticCOM, proteinAromaticCOM,\n",
    "                                              box=box)[0][0]\n",
    "\n",
    "                    if distance <= cutoff:\n",
    "                        numberOfContacts += 1\n",
    "\n",
    "                \"\"\"Export the data in the hdf5 file.\"\"\"\n",
    "                group.create_dataset(name=frameIdx, data=np.array([numberOfContacts]))\n",
    "                \n",
    "    def _residuesInBeta(self, simplified=False):\n",
    "        \"\"\"For this function, the package mdtraj is used as it enables to compute the secondary\n",
    "        structure using dssp. Please note that the simplified dssp codes ('simplified=True') \n",
    "        are ‘E’== Strand (either of the ‘E’, or ‘B’ non-simplified codes, which are ‘B’ : Residue\n",
    "        in isolated beta-bridge ‘E’ : Extended strand, participates in beta ladder.\"\"\"\n",
    "        \n",
    "        \"\"\"Load the trajectory using mdtraj as 'trajec'.\"\"\"\n",
    "        trajec = mdtraj.load(self.traj, top=self.top)\n",
    "\n",
    "        \"\"\"Open the hdf5 file and create the group 'residuesInBeta' to store all information\n",
    "        for this descriptor function. The structure of this group is (nFrames, nChains).\"\"\"\n",
    "        with h5.File(self.h5File, 'a') as f:\n",
    "            group = f.require_group(name='residuesInBeta')\n",
    "\n",
    "            \"\"\"Compute the secondary structures in each frame and count the 'E's (strands, when using\n",
    "            simplified code assignments).\"\"\"\n",
    "            for frameIdx, secondaryStructure in enumerate(mdtraj.compute_dssp(trajec, simplified=simplified)):\n",
    "                residuesInBeta = list()\n",
    "                for residuesInBetaChain in np.split(secondaryStructure, self.nProteinChains):\n",
    "                    residuesInBeta.append(np.count_nonzero(residuesInBetaChain == 'E'))\n",
    "                \n",
    "                \"\"\"Store the number of residues in beta for each frame in the hdf5 file.\"\"\"\n",
    "                group.create_dataset(name=str(frameIdx), data=residuesInBeta)\n",
    "   \n",
    "    def _residuesInHelix(self, simplified=False):\n",
    "        \"\"\"For this function, the package mdtraj is used as it enables to compute the secondary\n",
    "        structure using dssp. Please note that the simplified dssp codes ('simplified=True') \n",
    "        are ‘H’== Helix (either of the ‘H’, or ‘G’, or 'I' Helix codes, which are ‘H’ : Alpha helix\n",
    "        ‘G’ : 3-helix, 'I' : 5-helix participates in helical ladder.\"\"\"\n",
    "        \n",
    "        \"\"\"Load the trajectory using mdtraj as 'trajec'.\"\"\"\n",
    "        trajec = mdtraj.load(self.traj, top=self.top)\n",
    "\n",
    "        \"\"\"Open the hdf5 file and create the group 'residuesInHelix' to store all information\n",
    "        for this descriptor function. The structure of this group is (nFrames, nChains).\"\"\"\n",
    "        with h5.File(self.h5File, 'a') as f:\n",
    "            group = f.require_group(name='residuesInHelix')\n",
    "\n",
    "            \"\"\"Compute the secondary structures in each frame and count the 'H's (Helices, when using\n",
    "            simplified code assignments).\"\"\"\n",
    "            for frameIdx, secondaryStructure in enumerate(mdtraj.compute_dssp(trajec, simplified=simplified)):\n",
    "                residuesInHelix = list()\n",
    "                for residuesInHelixChain in np.split(secondaryStructure, self.nProteinChains):\n",
    "                    residuesInHelix.append(np.count_nonzero(residuesInHelixChain == 'H'))\n",
    "                \n",
    "                \"\"\"Store the number of residues in helices for each frame in the hdf5 file.\"\"\"\n",
    "                group.create_dataset(name=str(frameIdx), data=residuesInHelix)\n",
    "    \n",
    "    def _residuesInCoil(self, simplified=False):\n",
    "        \"\"\"For this function, the package mdtraj is used as it enables to compute the secondary\n",
    "        structure using dssp. Please note that the simplified dssp codes ('simplified=True') \n",
    "        are ‘C’== Coil (either of the ‘T’, or ‘S’, or '' Coil codes, which are ‘T’ : hydrogen bonded turn\n",
    "        ‘S’ : bend, '' : Loops and irregular elements, participates in random coil ladder.\"\"\"\n",
    "        \n",
    "        \"\"\"Load the trajectory using mdtraj as 'trajec'.\"\"\"\n",
    "        trajec = mdtraj.load(self.traj, top=self.top)\n",
    "\n",
    "        \"\"\"Open the hdf5 file and create the group 'residuesInCoil' to store all information\n",
    "        for this descriptor function. The structure of this group is (nFrames, nChains).\"\"\"\n",
    "        with h5.File(self.h5File, 'a') as f:\n",
    "            group = f.require_group(name='residuesInCoil')\n",
    "\n",
    "            \"\"\"Compute the secondary structures in each frame and count the 'C's (Coiled, when using\n",
    "            simplified code assignments).\"\"\"\n",
    "            for frameIdx, secondaryStructure in enumerate(mdtraj.compute_dssp(trajec, simplified=simplified)):\n",
    "                residuesInCoil = list()\n",
    "                for residuesInCoilChain in np.split(secondaryStructure, self.nProteinChains):\n",
    "                    residuesInCoil.append(np.count_nonzero(residuesInCoilChain == 'C'))\n",
    "                \n",
    "                \"\"\"Store the number of residues in random coils for each frame in the hdf5 file.\"\"\"\n",
    "                group.create_dataset(name=str(frameIdx), data=residuesInCoil)    \n",
    "                \n",
    "    def _generateTransitionMatrix(self):\n",
    "        \"\"\"Generate the key names for the state defining functions, which may either be composed\n",
    "        of the descriptors name or of the descriptors name and the associated cutoff value.\"\"\"\n",
    "        descriptorKeys = []\n",
    "        for descriptorName in self.state:\n",
    "            try:\n",
    "                descriptorKeys.append(descriptorName + str(self.descriptors[descriptorName]))\n",
    "            except KeyError:\n",
    "                descriptorKeys.append(descriptorName)\n",
    "        \n",
    "        differentStatesList = []\n",
    "        populationOfStatesDict = {}\n",
    "        transitionMatrixDict = {}\n",
    "        countIdx = 0\n",
    "        states = []\n",
    "        with h5.File(self.h5File, 'r') as f:\n",
    "            stateInFrame = []\n",
    "            for frame in range(self.nFrames):\n",
    "                \"\"\"Extract the states in every frame.\"\"\"\n",
    "                stateInFrame = []\n",
    "                for key in descriptorKeys:\n",
    "                    for value in f[key][str(frame)]:\n",
    "                        stateInFrame.append(int(value))\n",
    "                \n",
    "                \"\"\"If a state did not occur yet, append it to the list 'differenStatesList',\n",
    "                update its population and generate an entry in the dictionary \n",
    "                'transitionMatrixDict' to later relate the entries in the 'transitionMatrix' with\n",
    "                transitions between states, in other words to relate indices <-> states.\"\"\"\n",
    "                if (stateInFrame not in differentStatesList):\n",
    "                    differentStatesList.append(stateInFrame)\n",
    "                    populationOfStatesDict.update({tuple(stateInFrame): 1})\n",
    "                    transitionMatrixDict.update({tuple(stateInFrame): countIdx})\n",
    "                    countIdx += 1\n",
    "    \n",
    "                else:\n",
    "                    \"\"\"If a state is already known, increase its population by one\n",
    "                    update its population.\"\"\"\n",
    "                    population = populationOfStatesDict[tuple(stateInFrame)]\n",
    "                    population += 1\n",
    "                    populationOfStatesDict.update({tuple(stateInFrame): population})\n",
    "                \n",
    "                \"\"\"Append the states observed in this frame to the overall array 'states'.\"\"\"\n",
    "                states.append(tuple(stateInFrame))\n",
    "                                \n",
    "            \"\"\"Get the number of different states which have been observed along the\n",
    "            trajectory.\"\"\"\n",
    "            differentStates = len(differentStatesList)\n",
    "            states = np.array(states)\n",
    "            \n",
    "            \"\"\"Initialize the transition matrix.\"\"\"\n",
    "            transitionMatrix = np.zeros((differentStates, differentStates), dtype=int)\n",
    "            \n",
    "            \"\"\"Fill the transition matrix with transition values by counting all observed\n",
    "            transitions between two states.\"\"\"\n",
    "            \n",
    "            stateHistory = states\n",
    "            for state1, state2 in zip(stateHistory[:-1], stateHistory[1:]):\n",
    "                    idx1 = transitionMatrixDict[tuple(state1)]\n",
    "                    idx2 = transitionMatrixDict[tuple(state2)]\n",
    "                    transitionMatrix[idx1][idx2] += 1\n",
    "        return (transitionMatrix, transitionMatrixDict)\n",
    "    \n",
    "    def _generateNetwork(self, minPopulation=0.0, minTransition=0.0, gexfName=\"network.gexf\"):\n",
    "        \"\"\"This function generates a .gexf file which can be visualized using the\n",
    "        program 'Gephi'. This files contains the following information:\n",
    "            - population of a state can be visualized by a node's size\n",
    "            - the name of a node is the state\n",
    "            - the amount of transition between two states is encoded in the\n",
    "              line thickness\n",
    "            - the direction of the transition is read to be clockwise.\n",
    "            \n",
    "        Futhermore the user is asked to give 'minPopulation' as input, which is a threshold\n",
    "        for only considering nodes possesing with at least 'minPopulation'*100 percent population\n",
    "        of the maximum observed population\"\"\"\n",
    "        \n",
    "        \n",
    "        transitionMatrix, transitionMatrixDict = self._generateTransitionMatrix()\n",
    "        transitionMatrixNonDiagonal = transitionMatrix.copy()\n",
    "        for idx,_ in enumerate(transitionMatrixNonDiagonal):\n",
    "            transitionMatrixNonDiagonal[idx][idx] = 0\n",
    "                \n",
    "        \"\"\"Get the maximum values for a node pouplation and a transition.\"\"\"\n",
    "        maxPopulation = max(np.diag(transitionMatrix))\n",
    "        maxTransition = np.max(transitionMatrixNonDiagonal)\n",
    "        \n",
    "        \"\"\"Generate a dictionary with nodes and normalized population, which are at least greater than\n",
    "        'minPopulation'.\"\"\"\n",
    "        nodesDict = {}\n",
    "        for state, size in zip(transitionMatrixDict.keys(), np.diagonal(transitionMatrix)):\n",
    "            fraction = size/maxPopulation\n",
    "            if (fraction >= minPopulation):\n",
    "                nodesDict.update({state: size})\n",
    "\n",
    "        \"\"\"Only consider normalized transitions with a value of at least 'minTransition'.\"\"\"\n",
    "        edgesDict = {}\n",
    "        for state1, (idx1, row) in zip(transitionMatrixDict.keys(), enumerate(transitionMatrix)):\n",
    "            for state2, (idx2, transition) in zip(transitionMatrixDict.keys(), enumerate(row)):\n",
    "                if (idx1 != idx2 and transition != 0):\n",
    "                    if (state1 in nodesDict.keys() and state2 in nodesDict.keys()):\n",
    "                        fraction = transition/maxTransition\n",
    "                        if (fraction >= minTransition):\n",
    "                            edgesDict.update({(state1, state2): transition})\n",
    "\n",
    "        G = nx.DiGraph()\n",
    "        for k, v in nodesDict.items():\n",
    "            G.add_node(k, size=float(v))\n",
    "        for k, v in edgesDict.items():\n",
    "            G.add_edge(k[0], k[1], weight=float(v))\n",
    "        nx.draw(G)\n",
    "        nx.write_gexf(G, gexfName)\n",
    "        \n",
    "    \n",
    "    def _OSError(self, function):\n",
    "        try:\n",
    "            function()\n",
    "        except OSError:\n",
    "            pass\n",
    "        except ValueError:\n",
    "            pass\n",
    "        except RuntimeError:\n",
    "            pass\n",
    "        \n",
    "    def generateNetwork(self, minPopulation=0.0, minTransition=0.0, gexfName=\"network.gexf\"):\n",
    "        for state in self.state:\n",
    "\n",
    "            if (state == 'hydrophobicContacts'):\n",
    "                self._OSError(self._intermolecularContactPairs)\n",
    "                self._OSError(self._hydrophobicContacts)\n",
    "            \n",
    "            elif (state == 'hbondContacts'):\n",
    "                self._OSError(self._intermolecularContactPairs)\n",
    "                self._OSError(self._hbondContacts)\n",
    "                \n",
    "            elif (state == 'chargedContacts'):\n",
    "                self._OSError(self._intermolecularContactPairs)\n",
    "                self._OSError(self._chargedContacts)\n",
    "            \n",
    "            elif (state == 'aromaticStacking'):\n",
    "                self._OSError(self._aromaticStacking)\n",
    "            \n",
    "            elif (state == 'polarContacts'):\n",
    "                self._OSError(self._intermolecularContactPairs)\n",
    "                self._OSError(self._polarContacts)\n",
    "            \n",
    "            elif (state == 'allContacts'):\n",
    "                self._OSError(self._intermolecularContactPairs)\n",
    "                self._OSError(self._allContacts)\n",
    "            \n",
    "            elif (state == 'residuesInBeta'):\n",
    "                self._OSError(self._residuesInBeta)\n",
    "            \n",
    "            elif (state == 'residuesInHelix'):\n",
    "                self._OSError(self._residuesInHelix)\n",
    "            \n",
    "            elif (state == 'residuesInCoil'):\n",
    "                self._OSError(self._residuesInCoil)\n",
    "                \n",
    "        self._generateNetwork(minPopulation=minPopulation, minTransition=minTransition, gexfName=gexfName)\n",
    "    \n",
    "    \n",
    "    def correlationCoefficients(self):\n",
    "        descriptorKeys = []\n",
    "        for descriptorName in self.state:\n",
    "            try:\n",
    "                descriptorKeys.append(descriptorName + str(self.descriptors[descriptorName]))\n",
    "            except KeyError:\n",
    "                descriptorKeys.append(descriptorName)\n",
    "        \n",
    "        with h5.File(self.h5File, 'r') as f:\n",
    "            correlations = {}\n",
    "            for idxA, keyA in enumerate(descriptorKeys,1):\n",
    "                for keyB in descriptorKeys[idxA:]:\n",
    "                    valuesA = np.zeros((self.nFrames, 1))\n",
    "                    valuesB = valuesA.copy()\n",
    "                    \n",
    "                    for frame in range(self.nFrames):\n",
    "                        valA = list(f[keyA][str(frame)])\n",
    "                        valB = list(f[keyB][str(frame)])\n",
    "                        for a, b in zip(valA, valB):\n",
    "                            valuesA[frame] = a\n",
    "                            valuesB[frame] = b\n",
    "                    \n",
    "                    correlationCoefficients = 0\n",
    "                    for valsA, valsB in zip(valuesA.T, valuesB.T):\n",
    "                        correlationCoefficients = np.corrcoef(valsA, valsB)[0][1]\n",
    "                    correlations.update({keyA + '+' + keyB: np.mean(correlationCoefficients)})\n",
    "        return (correlations)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a cutoff is given with one decimal place, all others must also be given with one decimal place!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top ='asyn120to140.lig41.pdb'\n",
    "# traj ='test.dcd'\n",
    "# desc = {'hydrophobicContacts': 6.0,'hbondContacts': 4.0,'chargedContacts':6.0,'aromaticStacking': 6.0}\n",
    "# state = ['hydrophobicContacts','hbondContacts','chargedContacts','aromaticStacking']\n",
    "\n",
    "# nLigandChains = 1\n",
    "# nProteinChains = 1\n",
    "\n",
    "# tn = TransitionNetworks(top=top, traj=traj, desc=desc,\n",
    "#                         nLigandChains=nLigandChains,nProteinChains=nProteinChains,state=state,\n",
    "#                         h5File='all.hdf5')\n",
    "\n",
    "# tn.generateNetwork(minPopulation=0.0, minTransition=0.0, gexfName=\"all.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traj = 'traj_nowater_test.xtc'\n",
    "top = 'traj_nowater.pdb'\n",
    "\n",
    "desc = {'allContacts': 10.0}\n",
    "state = ['allContacts', 'residuesInBeta', 'residuesInHelix', 'residuesInCoil']\n",
    "\n",
    "nLigandChains = 294\n",
    "nProteinChains = 1\n",
    "\n",
    "tn = TransitionNetworks(top=top, traj=traj, desc=desc,\n",
    "                        nLigandChains=nLigandChains,nProteinChains=nProteinChains,state=state,\n",
    "                        h5File='all.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[]]\n",
      "[[]]\n",
      "[[]]\n",
      "[[]]\n",
      "[[]]\n",
      "[[[440, 16177], [441, 16177], [445, 16177], [440, 16178], [445, 16178]]]\n",
      "[[]]\n",
      "[[[440, 3311], [436, 3312], [440, 3312], [440, 3314], [440, 3315], [451, 3315], [436, 3316], [439, 3316], [440, 3316], [441, 3316], [442, 3316], [443, 3316], [444, 3316], [445, 3316], [447, 3316], [451, 3316], [440, 3317], [451, 3317], [439, 3318], [440, 3318], [444, 3318], [445, 3318], [451, 3318], [439, 3321], [440, 3321], [420, 4528], [424, 4528], [440, 13361], [439, 13362], [440, 13362], [441, 13362], [445, 13362], [440, 13363], [441, 13363], [440, 13370], [441, 13370], [445, 13370], [449, 13370], [451, 13370], [440, 13371], [441, 13371], [445, 13371]]]\n",
      "[[[424, 2778], [432, 2778], [395, 2912], [395, 2914], [395, 2919], [440, 3322], [433, 3714], [396, 4513], [422, 4513], [423, 4513], [424, 4513], [428, 4513], [429, 4513], [430, 4513], [431, 4513], [432, 4513], [433, 4513], [434, 4513], [429, 4514], [432, 4514], [433, 4514], [433, 4515], [429, 4516], [432, 4516], [433, 4516], [396, 4517], [422, 4517], [423, 4517], [424, 4517], [425, 4517], [426, 4517], [428, 4517], [429, 4517], [430, 4517], [431, 4517], [432, 4517], [433, 4517], [434, 4517], [394, 4518], [396, 4518], [398, 4518], [400, 4518], [422, 4518], [423, 4518], [424, 4518], [425, 4518], [426, 4518], [428, 4518], [429, 4518], [430, 4518], [431, 4518], [432, 4518], [433, 4518], [434, 4518], [424, 4519], [425, 4519], [428, 4519], [429, 4519], [430, 4519], [431, 4519], [432, 4519], [433, 4519], [434, 4519], [394, 4520], [396, 4520], [400, 4520], [419, 4520], [420, 4520], [421, 4520], [422, 4520], [423, 4520], [424, 4520], [425, 4520], [426, 4520], [427, 4520], [428, 4520], [429, 4520], [430, 4520], [431, 4520], [432, 4520], [433, 4520], [434, 4520], [396, 4521], [422, 4521], [423, 4521], [424, 4521], [425, 4521], [428, 4521], [429, 4521], [430, 4521], [431, 4521], [432, 4521], [433, 4521], [434, 4521], [424, 4522], [428, 4522], [429, 4522], [431, 4522], [432, 4522], [433, 4522], [422, 4523], [423, 4523], [424, 4523], [428, 4523], [429, 4523], [431, 4523], [432, 4523], [433, 4523], [396, 4524], [400, 4524], [419, 4524], [420, 4524], [421, 4524], [422, 4524], [423, 4524], [424, 4524], [425, 4524], [426, 4524], [427, 4524], [428, 4524], [429, 4524], [430, 4524], [431, 4524], [432, 4524], [433, 4524], [434, 4524], [394, 4525], [395, 4525], [396, 4525], [397, 4525], [398, 4525], [400, 4525], [422, 4525], [423, 4525], [424, 4525], [425, 4525], [426, 4525], [428, 4525], [429, 4525], [430, 4525], [431, 4525], [432, 4525], [433, 4525], [434, 4525], [394, 4526], [395, 4526], [396, 4526], [397, 4526], [398, 4526], [400, 4526], [422, 4526], [423, 4526], [424, 4526], [428, 4526], [429, 4526], [430, 4526], [431, 4526], [432, 4526], [433, 4526], [434, 4526], [392, 4527], [393, 4527], [394, 4527], [395, 4527], [396, 4527], [397, 4527], [398, 4527], [399, 4527], [400, 4527], [416, 4527], [419, 4527], [420, 4527], [421, 4527], [422, 4527], [423, 4527], [424, 4527], [425, 4527], [426, 4527], [427, 4527], [428, 4527], [429, 4527], [430, 4527], [431, 4527], [432, 4527], [433, 4527], [434, 4527], [394, 4528], [395, 4528], [396, 4528], [397, 4528], [398, 4528], [400, 4528], [422, 4528], [423, 4528], [424, 4528], [425, 4528], [428, 4528], [429, 4528], [430, 4528], [431, 4528], [432, 4528], [433, 4528], [434, 4528], [440, 10951], [441, 10951], [445, 10951], [441, 10952], [397, 11753], [394, 11754], [395, 11754], [396, 11754], [397, 11754], [398, 11754], [395, 11755], [397, 11755], [394, 11758], [395, 11758], [396, 11758], [397, 11758], [398, 11758], [433, 11758], [395, 11761], [396, 11761], [397, 11761], [394, 11763], [395, 11763], [396, 11763], [397, 11763], [398, 11763], [431, 11763], [432, 11763], [433, 11763], [395, 11764], [396, 11764], [397, 11764], [415, 13357], [416, 13357], [417, 13357], [419, 13357], [420, 13357], [421, 13357], [422, 13357], [423, 13357], [424, 13357], [425, 13357], [426, 13357], [428, 13357], [429, 13357], [432, 13357], [435, 13357], [437, 13357], [438, 13357], [416, 13358], [419, 13358], [420, 13358], [421, 13358], [422, 13358], [423, 13358], [424, 13358], [416, 13359], [419, 13359], [420, 13359], [421, 13359], [422, 13359], [423, 13359], [424, 13359], [404, 13360], [415, 13360], [416, 13360], [419, 13360], [420, 13360], [421, 13360], [422, 13360], [423, 13360], [424, 13360], [425, 13360], [429, 13360], [432, 13360], [415, 13361], [416, 13361], [417, 13361], [419, 13361], [420, 13361], [421, 13361], [422, 13361], [423, 13361], [424, 13361], [425, 13361], [426, 13361], [427, 13361], [428, 13361], [429, 13361], [431, 13361], [432, 13361], [433, 13361], [435, 13361], [438, 13361], [415, 13362], [416, 13362], [417, 13362], [418, 13362], [419, 13362], [420, 13362], [421, 13362], [422, 13362], [423, 13362], [424, 13362], [425, 13362], [426, 13362], [427, 13362], [428, 13362], [429, 13362], [430, 13362], [431, 13362], [432, 13362], [433, 13362], [435, 13362], [436, 13362], [437, 13362], [438, 13362], [400, 13363], [404, 13363], [415, 13363], [416, 13363], [417, 13363], [418, 13363], [419, 13363], [420, 13363], [421, 13363], [422, 13363], [423, 13363], [424, 13363], [425, 13363], [426, 13363], [427, 13363], [428, 13363], [429, 13363], [430, 13363], [431, 13363], [432, 13363], [433, 13363], [434, 13363], [435, 13363], [436, 13363], [437, 13363], [438, 13363], [416, 13364], [419, 13364], [420, 13364], [421, 13364], [422, 13364], [423, 13364], [424, 13364], [425, 13364], [426, 13364], [428, 13364], [429, 13364], [432, 13364], [416, 13365], [419, 13365], [420, 13365], [421, 13365], [422, 13365], [423, 13365], [424, 13365], [419, 13366], [420, 13366], [421, 13366], [422, 13366], [424, 13366], [416, 13367], [417, 13367], [419, 13367], [420, 13367], [421, 13367], [422, 13367], [423, 13367], [424, 13367], [426, 13367], [435, 13367], [436, 13367], [437, 13367], [438, 13367], [440, 13367], [441, 13367], [419, 13368], [420, 13368], [421, 13368], [424, 13368], [400, 13369], [403, 13369], [404, 13369], [408, 13369], [409, 13369], [413, 13369], [415, 13369], [416, 13369], [417, 13369], [418, 13369], [419, 13369], [420, 13369], [421, 13369], [422, 13369], [423, 13369], [424, 13369], [425, 13369], [426, 13369], [427, 13369], [428, 13369], [429, 13369], [431, 13369], [432, 13369], [433, 13369], [435, 13369], [436, 13369], [437, 13369], [438, 13369], [439, 13369], [440, 13369], [441, 13369], [395, 13370], [396, 13370], [399, 13370], [400, 13370], [401, 13370], [403, 13370], [404, 13370], [405, 13370], [408, 13370], [409, 13370], [413, 13370], [414, 13370], [415, 13370], [416, 13370], [417, 13370], [418, 13370], [419, 13370], [420, 13370], [421, 13370], [422, 13370], [423, 13370], [424, 13370], [425, 13370], [426, 13370], [427, 13370], [428, 13370], [429, 13370], [430, 13370], [431, 13370], [432, 13370], [433, 13370], [434, 13370], [435, 13370], [436, 13370], [437, 13370], [438, 13370], [439, 13370], [440, 13370], [441, 13370], [400, 13371], [403, 13371], [404, 13371], [408, 13371], [409, 13371], [413, 13371], [415, 13371], [416, 13371], [417, 13371], [418, 13371], [419, 13371], [420, 13371], [421, 13371], [422, 13371], [423, 13371], [424, 13371], [425, 13371], [426, 13371], [427, 13371], [428, 13371], [429, 13371], [431, 13371], [432, 13371], [435, 13371], [436, 13371], [437, 13371], [438, 13371], [439, 13371], [440, 13371], [441, 13371], [400, 13372], [403, 13372], [404, 13372], [408, 13372], [409, 13372], [413, 13372], [415, 13372], [416, 13372], [417, 13372], [418, 13372], [419, 13372], [420, 13372], [421, 13372], [422, 13372], [423, 13372], [424, 13372], [425, 13372], [426, 13372], [427, 13372], [428, 13372], [429, 13372], [430, 13372], [431, 13372], [432, 13372], [433, 13372], [434, 13372], [435, 13372], [436, 13372], [437, 13372], [438, 13372], [439, 13372], [440, 13372], [441, 13372], [442, 13372], [420, 13373], [424, 13373], [424, 13376], [419, 13377], [420, 13377], [422, 13377], [423, 13377], [424, 13377], [428, 13377], [429, 13377], [432, 13377], [433, 13377], [422, 13378], [424, 13378], [429, 13378], [420, 13379], [424, 13379], [424, 16172], [424, 16174], [419, 16187], [420, 16187], [421, 16187], [422, 16187], [424, 16187], [425, 16187], [426, 16187], [429, 16187], [419, 16188], [420, 16188], [421, 16188], [422, 16188], [424, 16188], [425, 16188], [426, 16188], [429, 16188], [419, 16189], [420, 16189], [421, 16189], [422, 16189], [424, 16189], [425, 16189], [426, 16189], [429, 16189], [419, 16190], [420, 16190], [421, 16190], [422, 16190], [423, 16190], [424, 16190], [425, 16190], [426, 16190], [428, 16190], [429, 16190], [430, 16190], [431, 16190], [432, 16190], [433, 16190], [417, 16191], [419, 16191], [420, 16191], [421, 16191], [422, 16191], [423, 16191], [424, 16191], [425, 16191], [426, 16191], [427, 16191], [428, 16191], [429, 16191], [430, 16191], [431, 16191], [432, 16191], [433, 16191], [434, 16191], [421, 16192], [422, 16192], [424, 16192], [425, 16192], [426, 16192], [428, 16192], [429, 16192], [430, 16192], [419, 16193], [420, 16193], [421, 16193], [422, 16193], [423, 16193], [424, 16193], [425, 16193], [426, 16193], [427, 16193], [428, 16193], [429, 16193], [430, 16193], [432, 16193], [421, 16194], [422, 16194], [424, 16194], [426, 16194], [429, 16194], [424, 16195], [429, 16195], [424, 16196], [429, 16196], [424, 16197], [429, 16197]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[420, 3060], [421, 3060], [424, 3060], [426, 3307], [429, 3307], [429, 3308], [424, 3309], [426, 3309], [429, 3309], [419, 3311], [421, 3311], [422, 3311], [424, 3311], [425, 3311], [426, 3311], [427, 3311], [428, 3311], [429, 3311], [430, 3311], [419, 3312], [421, 3312], [422, 3312], [424, 3312], [425, 3312], [426, 3312], [427, 3312], [428, 3312], [429, 3312], [430, 3312], [431, 3312], [432, 3312], [419, 3313], [421, 3313], [422, 3313], [424, 3313], [425, 3313], [426, 3313], [428, 3313], [429, 3313], [430, 3313], [419, 3314], [420, 3314], [421, 3314], [422, 3314], [423, 3314], [424, 3314], [425, 3314], [426, 3314], [427, 3314], [428, 3314], [429, 3314], [430, 3314], [431, 3314], [432, 3314], [434, 3314], [426, 3315], [428, 3315], [429, 3315], [430, 3315], [425, 3316], [426, 3316], [428, 3316], [429, 3316], [430, 3316], [422, 3317], [424, 3317], [425, 3317], [426, 3317], [428, 3317], [429, 3317], [430, 3317], [431, 3317], [432, 3317], [434, 3317], [429, 3318], [421, 10945], [440, 10945], [419, 10949], [420, 10949], [421, 10949], [435, 10949], [436, 10949], [437, 10949], [439, 10949], [440, 10949], [441, 10949], [419, 10950], [420, 10950], [421, 10950], [424, 10950], [435, 10950], [436, 10950], [437, 10950], [439, 10950], [440, 10950], [441, 10950], [419, 10951], [420, 10951], [421, 10951], [424, 10951], [435, 10951], [436, 10951], [439, 10951], [440, 10951], [441, 10951], [416, 10952], [417, 10952], [419, 10952], [420, 10952], [421, 10952], [422, 10952], [424, 10952], [426, 10952], [435, 10952], [436, 10952], [437, 10952], [438, 10952], [439, 10952], [440, 10952], [441, 10952], [442, 10952], [445, 10952], [421, 10953], [436, 10953], [440, 10953], [419, 10954], [420, 10954], [421, 10954], [435, 10954], [436, 10954], [437, 10954], [439, 10954], [440, 10954], [441, 10954], [445, 10954], [421, 10955], [440, 10955], [440, 10956], [439, 10957], [440, 10957], [441, 10957], [440, 10958], [420, 10959], [421, 10959], [435, 10959], [436, 10959], [437, 10959], [438, 10959], [439, 10959], [440, 10959], [441, 10959], [445, 10959], [440, 10960], [424, 13357], [420, 13360], [424, 13360], [424, 13361], [424, 13362], [424, 13363], [429, 13363], [419, 13369], [420, 13369], [421, 13369], [422, 13369], [423, 13369], [424, 13369], [426, 13369], [429, 13369], [416, 13370], [419, 13370], [420, 13370], [421, 13370], [422, 13370], [423, 13370], [424, 13370], [425, 13370], [426, 13370], [428, 13370], [429, 13370], [434, 13370], [419, 13371], [420, 13371], [421, 13371], [422, 13371], [423, 13371], [424, 13371], [426, 13371], [429, 13371], [419, 13372], [420, 13372], [421, 13372], [422, 13372], [423, 13372], [424, 13372], [425, 13372], [426, 13372], [428, 13372], [429, 13372]]]\n",
      "[[[441, 13361], [440, 13362], [441, 13362], [439, 13363], [440, 13363], [441, 13363], [445, 13363], [441, 13369], [445, 13369], [451, 13369], [439, 13370], [440, 13370], [441, 13370], [444, 13370], [445, 13370], [450, 13370], [451, 13370], [439, 13372], [440, 13372], [441, 13372], [445, 13372], [450, 13372], [451, 13372]]]\n"
     ]
    }
   ],
   "source": [
    "tn._intermolecularContactPairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tn.generateNetwork(minPopulation=0.0, minTransition=0.0, gexfName=\"10cutoff.gexf\")\n",
    "#tn.generateNetwork(minPopulation=0.0, minTransition=0.0, gexfName=\"8cutoff.gexf\")\n",
    "#tn.generateNetwork(minPopulation=0.0, minTransition=0.0, gexfName=\"5cutoff.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = tn.correlationCoefficients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'allContacts8.0+residuesInBeta': nan,\n",
       " 'allContacts8.0+residuesInHelix': nan,\n",
       " 'allContacts8.0+residuesInCoil': nan,\n",
       " 'residuesInBeta+residuesInHelix': nan,\n",
       " 'residuesInBeta+residuesInCoil': nan,\n",
       " 'residuesInHelix+residuesInCoil': nan}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5.File('all.hdf5', 'r') as f:\n",
    "    #print(list(f))\n",
    "    #print(list(f['hydrophobicContacts4.0']['1009']))\n",
    "    for frame in list(f['allContacts10.0']):\n",
    "            print(frame, list(f['allContacts10.0'][frame]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with h5.File('all.hdf5', 'r') as f:\n",
    "#     #print(list(f))\n",
    "#     #print(list(f['hydrophobicContacts4.0']['1009']))\n",
    "#     for frame in list(f['allContacts10.0']):\n",
    "#         if 1 not in f['allContacts10.0'][frame]:\n",
    "#             print(frame, list(f['allContacts.0'][frame]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tn._intermolecularContactPairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tn._aromaticStacking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tn._hydrophobicContacts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tn._chargedContacts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tn._hbondContacts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tn._polarContacts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with h5.File('test.hdf5', 'r') as f:\n",
    "#    for frame in range(1000):\n",
    "#        if f['hbondContacts3.5'][str(frame)][0] != 0:\n",
    "#            print(frame, f['hbondContacts3.5'][str(frame)][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tn.generateNetwork(minPopulation=0.01, minTransition=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aromatics = {'TYR': ['CG', 'CD1', 'CD2', 'CE1', 'CE2', 'CZ']}\n",
    "#\n",
    "#proteinAromaticCindex = []\n",
    "#tyr = []\n",
    "#ctyr = 0\n",
    "#for atom in tn.universe.atoms:\n",
    "#    if atom.resname == 'TYR':\n",
    "#        if atom.name in aromatics['TYR']:\n",
    "#            if ctyr < 5:\n",
    "#                tyr.append(atom.index)\n",
    "#                ctyr +=1\n",
    "#            else:\n",
    "#                tyr.append(atom.index)\n",
    "#                proteinAromaticCindex.append(tyr)\n",
    "#                tyr = []\n",
    "#               ctyr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ligandAromaticC = tn.universe.atoms[304:314]\n",
    "#ligandAromaticC.center_of_mass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ligandAromaticC.guess_bonds()\n",
    "#print(ligandAromaticC.bonds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ligand = tn.universe.atoms[nAtomsPerProteinChain:]\n",
    "#ligand.guess_bonds()\n",
    "#\n",
    "#elements = [atom.type for atom in ligand]\n",
    "#\n",
    "#pos = 0\n",
    "#neg = 0\n",
    "#for residue in tn.universe.residues:\n",
    "#    if residue.resname == 'LIG':\n",
    "#        for atom in residue.atoms:\n",
    "#            element = atom.type\n",
    "#            atomIdx = atom.index\n",
    "#            \n",
    "#            if (element == 'N'):\n",
    "#                bondingDegree = 0\n",
    "#                for bond in ligand.bonds:\n",
    "#                    if (atomIdx in ligand.indices):\n",
    "#                        bondingDegree += 1\n",
    "#                \n",
    "#                if (bondingDegree == 4):\n",
    "#                    pos += 1\n",
    "#            \n",
    "#            elif (element == 'O'):  \n",
    "#                bondingDegree = 0\n",
    "#                for bond in ligand.bonds:\n",
    "#                    if (atomIdx in ligand.indices):\n",
    "#                        bondingDegree += 1\n",
    "#                        \n",
    "#                if (bondingDegree == 1):\n",
    "#                    neg -= 1\n",
    "#\n",
    "#charge = pos + neg\n",
    "#print('Charge of ligand: ', charge)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
